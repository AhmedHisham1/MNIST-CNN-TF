{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_MNIST_TF.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "1x0GsBqVvKjC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YqxG-m4NIo3v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ee6d1679-9c23-4418-fa98-2910e6826ec4"
      },
      "cell_type": "code",
      "source": [
        "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oz4CUCxgevhd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_accuracy(v_xs, v_ys):\n",
        "    global prediction\n",
        "    \n",
        "    y_pre = sess.run(prediction, feed_dict={xs: v_xs, keep_prob: 1})\n",
        "    # Feeding xs=v_xs and keep_prob=1 to calculate (prediction = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2))\n",
        "    # where (h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)) >>> that's why we need to feed keep_prob, also (h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1))\n",
        "    # and (h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64]))...etc, until we reach (xs = tf.placeholder(tf.float32, [None, 784])/255.)\n",
        "    # and (keep_prob = tf.placeholder(tf.float32)). so basically we are feeding the inputs of the CNN which are v_xs in this case, and feeding\n",
        "    # the hyperparameter keep_prob as 1 and then forward propagation runs step by step until it predicts the input images' labels.\n",
        "    \n",
        "    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1)) \n",
        "    # tf.equal returns the truth value of tf.argmax(y_pre,1) == tf.argmax(v_ys,1) as a tensor of type bool\n",
        "    # note: tf.argmax returns the index with the largest value across axes of a tensor\n",
        "    \n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    # tf.cast(correct_prediction, tf.float32) casts a tensor to a new type(tf.float32 in this case). Because correct prediction was a tensor of type bool.\n",
        "    # tf.reduce_mean(...) computes the mean of elements across dimensions of a tensor. note: default value for axis=0, so it returns the mean of each column(one column anyway)\n",
        "    \n",
        "    result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys, keep_prob: 1})\n",
        "    # feeding the test_x and test_y values and the keep_prob hyperparameter to run the model and evaluate the accuracy; \n",
        "    # where as mentioned above (accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)))\n",
        "    # also: correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1)) >>> that's why we feed the test_y (v_ys)\n",
        "    # so the session runs and calculates the accuracy and stores it in the result tensor, which we then return.\n",
        "    \n",
        "    return result\n",
        "  \n",
        "  \n",
        "def print_confusion_matrix(v_xs, v_ys):\n",
        "    # Get the true classifications for the test-set.\n",
        "    cls_true = np.argmax(v_ys, 1)\n",
        "    # Get the predicted classifications for the test-set.\n",
        "    cls_pred = sess.run(prediction, feed_dict={xs: v_xs, keep_prob: 1})\n",
        "    cls_pred = np.argmax(cls_pred, 1)\n",
        "    # Get the confusion matrix using sklearn.\n",
        "    cm = confusion_matrix(y_true=cls_true, y_pred=cls_pred)\n",
        "#     cm = tf.confusion_matrix(labels=cls_true, predictions=cls_pred)\n",
        "    \n",
        "    # Print the confusion matrix as text.\n",
        "    # print(cm)\n",
        "    # Plot the confusion matrix as an image.\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    # Make various adjustments to the plot.\n",
        "    plt.tight_layout()\n",
        "    # plt.colorbar()\n",
        "    tick_marks = np.arange(10)\n",
        "    plt.xticks(tick_marks, range(10))\n",
        "    plt.yticks(tick_marks, range(10))\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "\n",
        "    \n",
        "  \n",
        "  \n",
        "\n",
        "def weight_variable(shape):\n",
        "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
        "    # another way(done by andrew ng):\n",
        "#     W = tf.get_variable(\"W\", shape, initializer=tf.contrib.layers.xavier_initializer(seed = 0))\n",
        "#     return W\n",
        "    return tf.Variable(initial)\n",
        "\n",
        "def bias_variable(shape):\n",
        "    initial = tf.constant(0.1, shape=shape)\n",
        "    return tf.Variable(initial)\n",
        "\n",
        "def conv2d(x, W):\n",
        "    # stride [1, x_movement, y_movement, 1]\n",
        "    # Must have strides[0] = strides[3] = 1\n",
        "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "def max_pool_2x2(x):\n",
        "    # stride [1, x_movement, y_movement, 1]\n",
        "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4MqmjEjzfrR5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# define placeholder for inputs to network\n",
        "xs = tf.placeholder(tf.float32, [None, 784])/255.   # 28x28\n",
        "ys = tf.placeholder(tf.float32, [None, 10])\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "x_image = tf.reshape(xs, [-1, 28, 28, 1])\n",
        "# print(x_image.shape)  # [n_samples, 28,28,1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RRR3byApgzJ7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "## conv1 layer ##\n",
        "W_conv1 = weight_variable([5,5, 1,32]) # patch 5x5, in size 1, out size 32\n",
        "b_conv1 = bias_variable([32])\n",
        "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) # output size 28x28x32\n",
        "h_pool1 = max_pool_2x2(h_conv1)                                         # output size 14x14x32\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uvw1hiZxg1kX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "## conv2 layer ##\n",
        "W_conv2 = weight_variable([5,5, 32, 64]) # patch 5x5, in size 32, out size 64\n",
        "b_conv2 = bias_variable([64])\n",
        "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) # output size 14x14x64\n",
        "h_pool2 = max_pool_2x2(h_conv2)                                         # output size 7x7x64\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xk_Atmr6g4eI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "## fc1 layer ##\n",
        "W_fc1 = weight_variable([7*7*64, 1024])\n",
        "b_fc1 = bias_variable([1024])\n",
        "# [n_samples, 7, 7, 64] ->> [n_samples, 7*7*64]\n",
        "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
        "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
        "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vXKUWSZeg68N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "## fc2 layer ##\n",
        "W_fc2 = weight_variable([1024, 10])\n",
        "b_fc2 = bias_variable([10])\n",
        "prediction = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WEYrx4w7g84g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# the error between prediction and real data\n",
        "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),\n",
        "                                              reduction_indices=[1]))       # loss\n",
        "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M7Ntm_X3hBwj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "87041eb9-0b7d-4d78-a954-9feabdd1935f"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "\n",
        "print('Batch Size = 100 training examples\\n1 Epoch = 600 batches = the whole 60000 training examples available in the MNIST dataset')\n",
        "\n",
        "num_epochs = 1\n",
        "for i in range(600 * num_epochs):\n",
        "    X_batch, Y_batch = mnist.train.next_batch(100)\n",
        "    #I defined every batch to be of 100 training examples, and since the mnist dataset has 60000 training examples, therefore every 600 batchs define an entire epoch\n",
        "    sess.run(train_step, feed_dict={xs: X_batch, ys: Y_batch, keep_prob: 0.5})\n",
        "    if i % 600 == 0 and i != 0:\n",
        "        # testing on the whole 10000 testing examples available in this dataset\n",
        "        print('Accuracy for {} epoch:'.format((i / 600)), end=' ')\n",
        "        print(compute_accuracy(mnist.test.images[:10000], mnist.test.labels[:10000]))\n",
        "        print('Confusion Matrix:')\n",
        "        print_confusion_matrix(mnist.test.images[:10000], mnist.test.labels[:10000])\n",
        "    elif i == (600*num_epochs-1):\n",
        "        print('Accuracy for {} epoch:'.format(( (i+1) / 600)), end=' ')\n",
        "        print(compute_accuracy(mnist.test.images[:10000], mnist.test.labels[:10000]))\n",
        "        print('Confusion Matrix:')\n",
        "        print_confusion_matrix(mnist.test.images[:10000], mnist.test.labels[:10000])\n",
        "\n",
        "        \n",
        "# to show the progress for every 50 batchs instead of the full epochs uncomment this:\n",
        "\n",
        "# num_epochs = 1\n",
        "# for i in range(600 * num_epochs):\n",
        "#     X_batch, Y_batch = mnist.train.next_batch(100)\n",
        "#     #we define every batch to be of 100 training examples, and since the mnist dataset has 60000 training examples, therefore every 600 batchs define an entire epoch\n",
        "#     sess.run(train_step, feed_dict={xs: X_batch, ys: Y_batch, keep_prob: 0.5})\n",
        "#     if i % 50 == 0:\n",
        "#         print('Accuracy for {} batchs:'.format((i / 50)), end=' ')\n",
        "#         print(compute_accuracy(mnist.test.images[:10000], mnist.test.labels[:10000]))\n",
        "#         print('Confusion Matrix:')\n",
        "#         print_confusion_matrix(mnist.test.images[:10000], mnist.test.labels[:10000])\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch Size = 100 training examples\n",
            "1 Epoch = 600 batches = the whole 60000 training examples available in the MNIST dataset\n",
            "Accuracy for 1.0 epoch: 0.9843\n",
            "Confusion Matrix:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAGOCAYAAACJ70QGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f344d6c14a8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Jr5Tq8b1hGcS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}